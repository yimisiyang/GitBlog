<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/gitblog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/gitblog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/gitblog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/gitblog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/gitblog/css/main.css">


<link rel="stylesheet" href="/gitblog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yimisiyang.github.io","root":"/gitblog/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1 Flink概述Apache Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。 1.1 Flink主要特点 事件驱动 基于流的世界观 在Flink世界观中，一切都是由流组成的，离线数据是有界的流；实时数据是一个没有界限的流：这就是所谓的有界流和无界流。   分层API 越顶层越抽象，表达含义越简明，使用越方便 越底层越具体，表达能力越丰富，使用越灵活 SQL&amp;#x2F">
<meta property="og:type" content="article">
<meta property="og:title" content="一米思阳的小屋">
<meta property="og:url" content="https://yimisiyang.github.io/gitblog/2022/04/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="一米思阳的小屋">
<meta property="og:description" content="1 Flink概述Apache Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。 1.1 Flink主要特点 事件驱动 基于流的世界观 在Flink世界观中，一切都是由流组成的，离线数据是有界的流；实时数据是一个没有界限的流：这就是所谓的有界流和无界流。   分层API 越顶层越抽象，表达含义越简明，使用越方便 越底层越具体，表达能力越丰富，使用越灵活 SQL&amp;#x2F">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304095628.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304101059.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304152937.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304154357.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305100636.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305101606.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305101934.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305200416.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305201240.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305201708.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305202449.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307092332.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307092948.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307095636.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307161040.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309113845.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309150909.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309161236.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309162652.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220310151305.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220310163815.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220310164149.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220311093501.png">
<meta property="og:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220311151027.png">
<meta property="article:published_time" content="2022-04-04T14:25:39.062Z">
<meta property="article:modified_time" content="2022-03-11T07:13:25.412Z">
<meta property="article:author" content="yimisiyang">
<meta property="article:tag" content="程序猿">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304095628.png">

<link rel="canonical" href="https://yimisiyang.github.io/gitblog/2022/04/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink%E5%AD%A6%E4%B9%A0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | 一米思阳的小屋</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/gitblog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">一米思阳的小屋</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/gitblog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/gitblog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yimisiyang.github.io/gitblog/2022/04/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/gitblog/images/avatar.gif">
      <meta itemprop="name" content="yimisiyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="一米思阳的小屋">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-04 22:25:39" itemprop="dateCreated datePublished" datetime="2022-04-04T22:25:39+08:00">2022-04-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-03-11 15:13:25" itemprop="dateModified" datetime="2022-03-11T15:13:25+08:00">2022-03-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-Flink概述"><a href="#1-Flink概述" class="headerlink" title="1 Flink概述"></a>1 Flink概述</h1><p>Apache Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。</p>
<h2 id="1-1-Flink主要特点"><a href="#1-1-Flink主要特点" class="headerlink" title="1.1 Flink主要特点"></a>1.1 Flink主要特点</h2><ul>
<li>事件驱动</li>
<li>基于流的世界观<ul>
<li>在Flink世界观中，一切都是由流组成的，离线数据是有界的流；实时数据是一个没有界限的流：这就是所谓的有界流和无界流。</li>
</ul>
</li>
<li>分层API<ul>
<li>越顶层越抽象，表达含义越简明，使用越方便</li>
<li>越底层越具体，表达能力越丰富，使用越灵活</li>
<li>SQL&#x2F;Table API -&gt; DataStream API -&gt;ProcessFunction (自顶向下)</li>
</ul>
</li>
</ul>
<p><strong>Flink其它特点</strong></p>
<ul>
<li>支持事件时间（event-time）和处理时间（processing-time）语义；</li>
<li>精确一次（exactly-once）的状态一致性保证；</li>
<li>低延迟，每秒处理数百万个事件，毫秒级延迟；</li>
<li>与众多常用存储系统的连接；</li>
<li>高可用，动态扩展，实现7*24小时全天候运行。</li>
</ul>
<h1 id="2-Flink-部署"><a href="#2-Flink-部署" class="headerlink" title="2 Flink 部署"></a>2 Flink 部署</h1><h2 id="2-1-Standalone模式"><a href="#2-1-Standalone模式" class="headerlink" title="2.1 Standalone模式"></a>2.1 Standalone模式</h2><h2 id="2-2-Yarn模式"><a href="#2-2-Yarn模式" class="headerlink" title="2.2 Yarn模式"></a>2.2 Yarn模式</h2><p>以Yarn 模式部署Flink任务时，要求Flink是有Hadoop支持的版本，Hadoop环境需要保证版本在2.2以上，并且集群中安装有HDFS服务。</p>
<h3 id="2-2-1-Flink-on-Yarn"><a href="#2-2-1-Flink-on-Yarn" class="headerlink" title="2.2.1 Flink on Yarn"></a>2.2.1 Flink on Yarn</h3><p>Flink提供了两种在yarn上运行的模式，分别为Session-Cluster和Per-Job-Cluster模式。</p>
<p>1）Session-Cluster模式</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304095628.png"></p>
<p>Session-Cluster模式需要先启动集群，然后在提交作业，接着会向yarn申请一块空间后，资源永远保持不变，如果资源满了，下一个作业就无法提交，只能等到yarn中的其中一个作业执行完成后，释放了资源，下个作业才会正常提交，所有作业共享Dispatcher和ResourceManager;共享资源，适合规模小执行作业时间短的作业。</p>
<p>在yarn中初始化一个flink集群，开辟指定的资源，以后提交任务都向这里提交。这个flink集群会常驻yarn集群中，除非手工停止。</p>
<p>2）Per-Job-Cluster模式</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304101059.png"></p>
<p>一个Job会对应一个集群，每提交一个作业会根据自身的情况，都会单独向yarn申请资源，直到作业执行完成，一个作业的失败与否并不会影响下一个作业的正常提交和运行。独享Dispatcher和ResourceManager，按需接受资源申请；适合规模大长时间运行的作业。</p>
<p>每次提交都会创建一个新的flink集群，任务之间互相独立，互不影响，方便管理。任务执行完成之后创的集群也会消失。</p>
<h3 id="2-2-2-Session-Cluster-模式启动"><a href="#2-2-2-Session-Cluster-模式启动" class="headerlink" title="2.2.2 Session Cluster 模式启动"></a>2.2.2 Session Cluster 模式启动</h3><ol>
<li><p>启动Hadoop集群</p>
</li>
<li><p>启动yarn-session</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./yarn-session.sh -n 2 -s 2 -jm 1024 -tm 1024 -nm test -d</span><br></pre></td></tr></table></figure>

<p>-n (–container): TaskManager的数量（可能已弃用）</p>
<p>-s (–slots): 每个TaskManager的slot 数量，默认一个slot一个core,默认每个taskmanager的slot的个数为1，有时可以多一些taskmanager，做冗余。</p>
<p>-jm: JobManager的内存（单位：MB）</p>
<p>-tm:每个taskmanager的内存（单位MB）</p>
<p>-nm: yarn的appName(现在yarn的ui上的名字)</p>
<p>-d: 后台执行</p>
</li>
<li><p>执行任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./flink run -c com.atguigu.wc.StreamWordCount FlinkTutorial-1.0-SNAPSHOT-jar-with-dependencies.jar --host localhost -port 7777</span><br></pre></td></tr></table></figure>
</li>
<li><p>去yarn 控制台查看任务状态</p>
</li>
<li><p>取消yarn-session</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn application --kill 作业id</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-3-Per-Job-Cluster-模式启动"><a href="#2-2-3-Per-Job-Cluster-模式启动" class="headerlink" title="2.2.3 Per Job Cluster 模式启动"></a>2.2.3 Per Job Cluster 模式启动</h3><ol>
<li><p>启动hadoop集群</p>
</li>
<li><p>不启动yarn-session,直接执行job</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./flink run -m yarn-cluster -c com.atguigu.wc.StreamWordCount FlinkTutorial-1.0-SNAPSHOT-jar-with-dependencies.jar --host localhost -port 7777</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-3-Kubernetes部署"><a href="#2-3-Kubernetes部署" class="headerlink" title="2.3 Kubernetes部署"></a>2.3 Kubernetes部署</h2><p>容器化部署时目前业界很流行的一项技术，基于Docker镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是Kubernetes，而Flink也在最近的版本中支持了k8s部署模式。</p>
<ol>
<li><p>搭建kubernetes集群</p>
</li>
<li><p>配置各组件的yaml文件</p>
<p>在k8s上构建Flink Session Cluster，需要将Flink集群的组件对应的docker镜像分别在k8s上启动，包括 JobManager、TaskManager、JobManagerService三个镜像服务，每个镜像服务都可以从中央仓库中获取</p>
</li>
<li><p>启动Flink Session Cluster</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动jobmanager-service服务</span></span><br><span class="line">kubectl create -f jobmanager-service.ymal</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动jobmanager-deployment服务</span></span><br><span class="line">kubectl create -f jobmanager-deployment.yaml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动taskmanager-deployment服务</span></span><br><span class="line">kubectl create -f taskmanager-deployment.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>访问Flink UI 页面</p>
</li>
</ol>
<h1 id="3-Flink-运行架构"><a href="#3-Flink-运行架构" class="headerlink" title="3 Flink 运行架构"></a>3 Flink 运行架构</h1><h2 id="3-1-Flink运行时的组件"><a href="#3-1-Flink运行时的组件" class="headerlink" title="3.1 Flink运行时的组件"></a>3.1 Flink运行时的组件</h2><ul>
<li>作业管理器（JobManager）<ul>
<li>控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行</li>
<li>JobManager会先接收到要执行的应用程序，这个应用程序会包括：作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的JAR包。</li>
<li>JobManager会把JobGraph转换为一个物理层面的数据流图，这个图被叫做“执行图（ExecutionGraph）”,包含了所有可以并发执行的任务。</li>
<li>JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到整整运行它们的TaskManager上。而在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</li>
</ul>
</li>
<li>任务管理器（TaskManager）<ul>
<li>Flink中的工作进程。通常在Flink中会有多个TaskManageri运行，每一个TaskManager都包含了一定数量的插槽(slots)。插槽的数量限制了TaskManager能够执行的任务数量。</li>
<li>启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给<br>JobManager调用。JobManager就可以向插槽分配任务(tasks)来执行了。</li>
<li>在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据。</li>
</ul>
</li>
<li>资源管理器（ResourceManager）<ul>
<li>主要负责管理任务管理器(TaskManager)的插槽(slot),TaskManger插槽是Flink中定义的处理资源单元。</li>
<li>FIik为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s,以及standalone部署。</li>
<li>当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager。如果ResourceManageri没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，<br>以提供启动TaskManageri进程的容器。</li>
</ul>
</li>
<li>分发器（Dispacher）<ul>
<li>可以跨作业运行，它为应用提交提供了REST接口。</li>
<li>当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。</li>
<li>Dispatchert也会启动一个Web Ul,用来方便地展示和监控作业执<br>行的信息。</li>
<li>Dispatcher在架构中可能并不是必需的，这取决于应用提交运行<br>的方式。</li>
</ul>
</li>
</ul>
<h2 id="3-2-任务提交流程"><a href="#3-2-任务提交流程" class="headerlink" title="3.2 任务提交流程"></a>3.2 任务提交流程</h2><p><strong>standlone模式</strong></p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304152937.png"></p>
<p><strong>Yarn模式</strong></p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220304154357.png"></p>
<h2 id="3-3-任务调度原理"><a href="#3-3-任务调度原理" class="headerlink" title="3.3 任务调度原理"></a>3.3 任务调度原理</h2><p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305100636.png"></p>
<h3 id="3-3-1-并行度"><a href="#3-3-1-并行度" class="headerlink" title="3.3.1 并行度"></a>3.3.1 并行度</h3><p>一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。一般情况下，一个stream的并行度，可以认为就是其所有算子中最大的并行度。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305101606.png"></p>
<p>Flink中每一个TaskManager都是一个JVM进程，它可能会在独立的线程上执行一个或多个子任务</p>
<p>为了控制一个TaskManager能接收多少个task, TaskManager通过task slot来进行控制（一个TaskManager至少有一个slot）,推荐使用CPU核心数来设置TaskManager 的slot数量，这样相当于一个slot占用一个核心，任务不需要等待。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305101934.png"></p>
<p>默认情况下，Flink允许子任务共享slot, 即使它们是不同任务的子任务。这样的结果是，一个slot可以保存作业的整个管道。</p>
<p>Task Slot是静态的概念，是指TaskManager具有的并发执行能力。</p>
<h3 id="3-3-2-程序与数据流（DataFlow）"><a href="#3-3-2-程序与数据流（DataFlow）" class="headerlink" title="3.3.2 程序与数据流（DataFlow）"></a>3.3.2 程序与数据流（DataFlow）</h3><p>所有的Flink程序都是由三部分组成的：Source、Transformation、Sink。</p>
<p>source负责读取数据源，Transformation利用各种算子进行处理加工，Sink负责输出。</p>
<h1 id="4-Flink流处理API"><a href="#4-Flink流处理API" class="headerlink" title="4 Flink流处理API"></a>4 Flink流处理API</h1><p><strong>每个Flink程序包含以下几个基本部分：</strong></p>
<ol>
<li>创建执行环境</li>
<li>创建&#x2F;加载初始数据</li>
<li>指定对数据所作的转换</li>
<li>指定计算结果的输出位置</li>
<li>触发程序的执行</li>
</ol>
<h2 id="4-1-创建执行环境"><a href="#4-1-创建执行环境" class="headerlink" title="4.1 创建执行环境"></a>4.1 创建执行环境</h2><p><code>StreamExecutionEnvironment</code>是所有Flink程序的基础，可以通过<code>StreamExecutionEnvironment</code>中的以下静态方法创建执行环境。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">getExecutionEnvironment()</span><br><span class="line"></span><br><span class="line">createLocalEnvironment()</span><br><span class="line"></span><br><span class="line">createRemoteEnvironment(String host, <span class="type">int</span> port, String... jarFiles)</span><br></pre></td></tr></table></figure>

<p>通常情况下使用getExecutionEnvironment()创建执行环境；</p>
<p>如果你的程序在IDE中执行（本地执行），也可以使用createLocalEnvironment()创建执行环境。</p>
<p>createRemoteEnvironment(String host, int port, String… jarFiles)返回集群执行环境，将Jar提交到远程服务器，需要在调用时指定JobManager的IP和端口号，并指定要在集群中运行的Jar包。</p>
<p><strong>举例：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 没有设置并行度，默认并行度为1</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataStream&lt;String&gt; text = env.readTextFile(<span class="string">&quot;file:///path/to/file&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="4-2-读取数据源"><a href="#4-2-读取数据源" class="headerlink" title="4.2 读取数据源"></a>4.2 读取数据源</h2><h3 id="4-2-1-从集合读取数据"><a href="#4-2-1-从集合读取数据" class="headerlink" title="4.2.1 从集合读取数据"></a>4.2.1 从集合读取数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.source;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/4</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 19:35</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceTest1_Collection</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment</span><br><span class="line">                .getExecutionEnvironment()</span><br><span class="line">                .setParallelism(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 从集合中读取数据,包装成DataStream</span></span><br><span class="line">        DataStreamSource&lt;SensorReading&gt; dataStreamSource = env.fromCollection(Arrays.asList(</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">SensorReading</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">154778199L</span>, <span class="number">35.2</span>),</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">SensorReading</span>(<span class="string">&quot;sensor_6&quot;</span>, <span class="number">154778201L</span>, <span class="number">32.5</span>),</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">SensorReading</span>(<span class="string">&quot;sensor_7&quot;</span>, <span class="number">154778223L</span>, <span class="number">33.4</span>),</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">SensorReading</span>(<span class="string">&quot;sensor_10&quot;</span>, <span class="number">154778245L</span>, <span class="number">30.1</span>)</span><br><span class="line">                )</span><br><span class="line">        );</span><br><span class="line">        <span class="comment">// 打印输出</span></span><br><span class="line">        dataStreamSource.print(<span class="string">&quot;data&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute(<span class="string">&quot;list&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;                                </span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-从文本中读取数据"><a href="#4-2-2-从文本中读取数据" class="headerlink" title="4.2.2 从文本中读取数据"></a>4.2.2 从文本中读取数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.source;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.ExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> * 从文件中读取数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/4</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 19:59</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceTest2_File</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">// 设置并行度，为了保证有序可以设置并行度为1</span></span><br><span class="line">        env.setParallelism(<span class="number">4</span>);</span><br><span class="line">        <span class="comment">//从文件中读取数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">inputPath</span> <span class="operator">=</span> <span class="string">&quot;F:\\Program\\FlinkProgram\\src\\main\\resources\\sensor.txt&quot;</span>;</span><br><span class="line">        DataStream&lt;String&gt; dataStream = env.readTextFile(inputPath);</span><br><span class="line">        <span class="comment">// 打印输出</span></span><br><span class="line">        dataStream.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3-从socket流中读取数据"><a href="#4-2-3-从socket流中读取数据" class="headerlink" title="4.2.3 从socket流中读取数据"></a>4.2.3 从socket流中读取数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.source;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/5</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 10:08</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceTest4_Socket</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dataStream = env</span><br><span class="line">                .socketTextStream(<span class="string">&quot;182.92.57.11&quot;</span>, <span class="number">7777</span>)</span><br><span class="line">                .flatMap(<span class="keyword">new</span> <span class="title class_">Splitter</span>())</span><br><span class="line">                .keyBy(value -&gt; value.f0)</span><br><span class="line">                .window(TumblingProcessingTimeWindows.of(Time.seconds(<span class="number">5</span>)))</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        dataStream.print();</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">&quot;Window WordCount&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Splitter</span> <span class="keyword">implements</span> <span class="title class_">FlatMapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt; &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String sentence, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="keyword">for</span> (String word: sentence.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">                out.collect(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(word, <span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-从kafka中读取数据"><a href="#4-2-4-从kafka中读取数据" class="headerlink" title="4.2.4 从kafka中读取数据"></a>4.2.4 从kafka中读取数据</h3><p>引入Kafka连接器的依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-connector-kafka --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink-version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>编写代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.source;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.WatermarkStrategy;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.KafkaSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/4</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 20:16</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceTest3_Kafka</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="comment">//创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">// 设置并行度</span></span><br><span class="line">        env.setParallelism(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//从kafka中读取数据</span></span><br><span class="line">        KafkaSource&lt;String&gt; source = KafkaSource.&lt;String&gt;builder()</span><br><span class="line">                .setBootstrapServers(<span class="string">&quot;39.97.181.124:9092&quot;</span>)</span><br><span class="line">                .setTopics(<span class="string">&quot;sensor&quot;</span>)</span><br><span class="line">                .setStartingOffsets(OffsetsInitializer.earliest())</span><br><span class="line">                .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>())</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;String&gt; dataStream = env.fromSource(source, WatermarkStrategy.noWatermarks(), <span class="string">&quot;Kafka Source&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//打印输出</span></span><br><span class="line">        dataStream.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-5-从RabbitMQ中读取数据"><a href="#4-2-5-从RabbitMQ中读取数据" class="headerlink" title="4.2.5 从RabbitMQ中读取数据"></a>4.2.5 从RabbitMQ中读取数据</h3><p>引入相关的依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-rabbitmq_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.14.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>RabbitMQ数据源提供三种不同级别来保证安全，具体如下：</p>
<ul>
<li>Exactly-once：为了使RabbitMQ源实现恰好一次保证，需要做以下设置<ul>
<li>开启checkpointing</li>
<li>使用correlation id</li>
<li>非并行源</li>
</ul>
</li>
<li>At-least-once:当checkpoint开启，但是correlation id没有设置或者源是并行的时候，能够保证At-least-once</li>
<li>No guarantee:checkpoint未开启时，源没有任何强有力的保证。</li>
</ul>
<p>编写代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// checkpointing is required for exactly-once or at-least-once guarantees</span></span><br><span class="line">env.enableCheckpointing(...);</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="type">RMQConnectionConfig</span> <span class="variable">connectionConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RMQConnectionConfig</span>.Builder()</span><br><span class="line">    .setHost(<span class="string">&quot;localhost&quot;</span>)</span><br><span class="line">    .setPort(<span class="number">5000</span>)</span><br><span class="line">    ...</span><br><span class="line">    .build();</span><br><span class="line">    </span><br><span class="line"><span class="keyword">final</span> DataStream&lt;String&gt; stream = env</span><br><span class="line">    .addSource(<span class="keyword">new</span> <span class="title class_">RMQSource</span>&lt;String&gt;(</span><br><span class="line">        connectionConfig,            <span class="comment">// config for the RabbitMQ connection</span></span><br><span class="line">        <span class="string">&quot;queueName&quot;</span>,                 <span class="comment">// name of the RabbitMQ queue to consume</span></span><br><span class="line">        <span class="literal">true</span>,                        <span class="comment">// use correlation ids; can be false if only at-least-once is required</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>()))   <span class="comment">// deserialization schema to turn messages into Java objects</span></span><br><span class="line">    .setParallelism(<span class="number">1</span>);              <span class="comment">// non-parallel source is only required for exactly-once</span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-6-自定义数据源"><a href="#4-2-6-自定义数据源" class="headerlink" title="4.2.6 自定义数据源"></a>4.2.6 自定义数据源</h3><p>自定义数据源要实现SourceFunction接口：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.source;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.SourceFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2022/3/5</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 16:36</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceTest5Udf</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">environment</span> <span class="operator">=</span> StreamExecutionEnvironment</span><br><span class="line">                .getExecutionEnvironment()</span><br><span class="line">                .setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//添加自定义数据源</span></span><br><span class="line">        DataStream&lt;SensorReading&gt; dataStream = environment.addSource(<span class="keyword">new</span> <span class="title class_">MySensorSource</span>());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//打印输出</span></span><br><span class="line">        dataStream.print();</span><br><span class="line">        <span class="comment">//执行</span></span><br><span class="line">        environment.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 实现自定义数据源</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MySensorSource</span> <span class="keyword">implements</span> <span class="title class_">SourceFunction</span>&lt;SensorReading&gt;&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定义一个退出标志位</span></span><br><span class="line">        <span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">running</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(SourceContext&lt;SensorReading&gt; ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="comment">//定义一个随机数发生器</span></span><br><span class="line">            <span class="type">Random</span> <span class="variable">random</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//设置10个传感器的初始温度值</span></span><br><span class="line">            HashMap&lt;String, Double&gt; sensorTemMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">                sensorTemMap.put(<span class="string">&quot;sensor_&quot;</span> + (i+<span class="number">1</span>), <span class="number">60</span> + random.nextGaussian() * <span class="number">20</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (running == <span class="literal">true</span>)&#123;</span><br><span class="line">                <span class="keyword">for</span> (String sensorId: sensorTemMap.keySet()) &#123;</span><br><span class="line">                    <span class="comment">// 在当前温度基础上随机波动</span></span><br><span class="line">                    <span class="type">double</span> <span class="variable">newTemp</span> <span class="operator">=</span> sensorTemMap.get(sensorId) + random.nextGaussian();</span><br><span class="line">                    sensorTemMap.put(sensorId, newTemp);</span><br><span class="line">                    ctx.collect(<span class="keyword">new</span> <span class="title class_">SensorReading</span>(sensorId, System.currentTimeMillis(),newTemp));</span><br><span class="line">                &#125;</span><br><span class="line">                Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">cancel</span><span class="params">()</span> &#123;</span><br><span class="line">            running = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-3-转换算子"><a href="#4-3-转换算子" class="headerlink" title="4.3 转换算子"></a>4.3 转换算子</h2><h3 id="4-3-1-map算子"><a href="#4-3-1-map算子" class="headerlink" title="4.3.1 map算子"></a>4.3.1 map算子</h3><p>转换过程：从DataStream–&gt;DataStream</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305200416.png"></p>
<p>输入为一个元素，输出为一个新的元素。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; dataStream = <span class="comment">//...</span></span><br><span class="line">dataStream.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;Integer, Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(Integer value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="4-3-2-FlatMap-算子"><a href="#4-3-2-FlatMap-算子" class="headerlink" title="4.3.2  FlatMap 算子"></a>4.3.2  FlatMap 算子</h3><p>转换过程：DataStream-&gt;DataStream</p>
<p>FaltMap可以先把输入的集合元素压扁flat,变成一个一个的元素，再将每一个元素进行map操作，最后将转换后的元素组成一个新的集合返回来。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305201240.png"></p>
<p>如上图所示：白框不变，黑框复制，灰框过滤。</p>
<p>输入为一个元素，输出可以为0个，1个或多个元素</p>
<p>flatmap可以实现map和filter。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dataStream.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String value, Collector&lt;String&gt; out)</span></span><br><span class="line">        <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">for</span>(String word: value.split(<span class="string">&quot; &quot;</span>))&#123;</span><br><span class="line">            out.collect(word);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="4-3-3-Filter-算子"><a href="#4-3-3-Filter-算子" class="headerlink" title="4.3.3 Filter 算子"></a>4.3.3 Filter 算子</h3><p>转换过程：DataStream-&gt;DataStream</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305201708.png"></p>
<p>过滤流中的元素，条件为true的过滤掉。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataStream.filter(<span class="keyword">new</span> <span class="title class_">FilterFunction</span>&lt;Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">filter</span><span class="params">(Integer value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> value != <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="4-3-4-KeyBy算子"><a href="#4-3-4-KeyBy算子" class="headerlink" title="4.3.4 KeyBy算子"></a>4.3.4 KeyBy算子</h3><p>转换过程：DataStream-&gt;KeyedStream</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220305202449.png"></p>
<p>逻辑地将一个流拆分成不相交的分区，每个分区包含具有相同key的元素，在内部以hash的形式实现的。</p>
<p>指定key有以下两种方式：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(value -&gt; value.getSomeKey());</span><br><span class="line">dataStream.keyBy(value -&gt; value.f0);</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>以下两种类型不能作为key</p>
<ol>
<li>POJO类型，但是没有实现它的hashCode方法</li>
<li>任意类型的数组</li>
</ol>
<p>在Flink中，只有对数据进行分组之后才能做聚合操作，也只有这样做才有意义。</p>
<h4 id="4-3-4-1-滚动聚合算子（Rolling-Aggregation）"><a href="#4-3-4-1-滚动聚合算子（Rolling-Aggregation）" class="headerlink" title="4.3.4.1 滚动聚合算子（Rolling Aggregation）"></a>4.3.4.1 滚动聚合算子（Rolling Aggregation）</h4><p>下面这些算子可以针对KeyedStream的每一个支流做聚合</p>
<ul>
<li>sum()</li>
<li>min()</li>
<li>max()</li>
<li>minBy()</li>
<li>maxBy()</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.transform;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.KeySelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/16</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 21:31</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransformTest2_RollingAggregation</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//1.构建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//2.读取数据源</span></span><br><span class="line">        DataStreamSource&lt;String&gt; inputStream = env.readTextFile(<span class="string">&quot;F:\\Program\\FlinkProgram\\src\\main\\resources\\sensor.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 转换成SensorReading类型</span></span><br><span class="line">        DataStream&lt;SensorReading&gt; dataStream = inputStream.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, SensorReading&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> SensorReading <span class="title function_">map</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                String[] fields = value.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SensorReading</span>(fields[<span class="number">0</span>],<span class="keyword">new</span> <span class="title class_">Long</span>(fields[<span class="number">1</span>]),<span class="keyword">new</span> <span class="title class_">Double</span>(fields[<span class="number">2</span>]));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.分组</span></span><br><span class="line">        <span class="comment">//KeyedStream&lt;SensorReading, Tuple&gt; keyedStream = dataStream.keyBy(&quot;id&quot;);</span></span><br><span class="line">        KeyedStream&lt;SensorReading, String&gt; keyedStream = dataStream.keyBy((KeySelector&lt;SensorReading, String&gt;) SensorReading::getId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.滚动聚合</span></span><br><span class="line">        SingleOutputStreamOperator&lt;SensorReading&gt; resultStream = keyedStream.maxBy(<span class="string">&quot;temperature&quot;</span>);</span><br><span class="line">        resultStream.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="4-3-4-2-Reduce"><a href="#4-3-4-2-Reduce" class="headerlink" title="4.3.4.2 Reduce"></a>4.3.4.2 Reduce</h4><p>KeyedStream-&gt;DataStream: 一个分组数据流的聚合操作，合并当前的元素和上次聚合的结果，产生一个新的值，返回的流中包含每一次聚合的结果，而不是只返回最后一次聚合的最终结果。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.transform;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.ReduceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.KeySelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/29</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 19:36</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransformTest3_Reduce</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//1.构建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//2.读取数据源</span></span><br><span class="line">        DataStreamSource&lt;String&gt; inputStream = env.readTextFile(<span class="string">&quot;F:\\Program\\FlinkProgram\\src\\main\\resources\\sensor.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 转换成SensorReading类型</span></span><br><span class="line">        DataStream&lt;SensorReading&gt; streamOperator = inputStream.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, SensorReading&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> SensorReading <span class="title function_">map</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                String[] split = value.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> (<span class="keyword">new</span> <span class="title class_">SensorReading</span>(split[<span class="number">0</span>], <span class="keyword">new</span> <span class="title class_">Long</span>(split[<span class="number">1</span>]), <span class="keyword">new</span> <span class="title class_">Double</span>(split[<span class="number">2</span>])));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.分组</span></span><br><span class="line">        KeyedStream&lt;SensorReading, String&gt; keyedStream = streamOperator.keyBy((KeySelector&lt;SensorReading, String&gt;) SensorReading::getId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.分组聚合（取最大温度值以及最新的时间戳）,value1为前面聚合出来的数据，value2为最新的数据</span></span><br><span class="line">        keyedStream.reduce(<span class="keyword">new</span> <span class="title class_">ReduceFunction</span>&lt;SensorReading&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> SensorReading <span class="title function_">reduce</span><span class="params">(SensorReading value1, SensorReading value2)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> (<span class="keyword">new</span> <span class="title class_">SensorReading</span>(value1.getId(), value2.getTimestamp(), Math.max(value1.getTemperature(),value2.getTemperature())));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.执行</span></span><br><span class="line">        env.execute(<span class="string">&quot;ReduceJob&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-3-5-多流转换算子"><a href="#4-3-5-多流转换算子" class="headerlink" title="4.3.5 多流转换算子"></a>4.3.5 多流转换算子</h3><h4 id="4-3-5-1-Connect-amp-amp-CoMap-amp-amp-CoFlatMap"><a href="#4-3-5-1-Connect-amp-amp-CoMap-amp-amp-CoFlatMap" class="headerlink" title="4.3.5.1 Connect&amp;&amp;CoMap&amp;&amp;CoFlatMap"></a>4.3.5.1 Connect&amp;&amp;CoMap&amp;&amp;CoFlatMap</h4><p><strong>Connect:</strong></p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307092332.png"></p>
<p>DataStream-&gt;ConnectedStream:连接两个保持它们类型的数据流，两个数据流被Connect之后，只是被放在了一个同一个流中，内部依然保持各自的数据和形式不发生任何变化，两个流相互独立。</p>
<p>Connect算子操作之后，需要使用CoMap或CoFlatMap将两个流和在一起。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; someStream = <span class="comment">//...</span></span><br><span class="line">DataStream&lt;String&gt; otherStream = <span class="comment">//...</span></span><br><span class="line"></span><br><span class="line">ConnectedStreams&lt;Integer, String&gt; connectedStreams = someStream.connect(otherStream);</span><br></pre></td></tr></table></figure>



<p><strong>CoMap或CoFlatMap</strong></p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307092948.png"></p>
<p>ConnectedStreams-&gt;DataStream:作用于ConnectedStream上，功能与map和flatmap一样，对ConnectedStream中的每一个Stream分别进行map和flatMap处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">connectedStreams.map(<span class="keyword">new</span> <span class="title class_">CoMapFunction</span>&lt;Integer, String, Boolean&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Boolean <span class="title function_">map1</span><span class="params">(Integer value)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Boolean <span class="title function_">map2</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">connectedStreams.flatMap(<span class="keyword">new</span> <span class="title class_">CoFlatMapFunction</span>&lt;Integer, String, String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap1</span><span class="params">(Integer value, Collector&lt;String&gt; out)</span> &#123;</span><br><span class="line">       out.collect(value.toString());</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap2</span><span class="params">(String value, Collector&lt;String&gt; out)</span> &#123;</span><br><span class="line">       <span class="keyword">for</span> (String word: value.split(<span class="string">&quot; &quot;</span>)) &#123;</span><br><span class="line">         out.collect(word);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h4 id="4-3-5-2-Union"><a href="#4-3-5-2-Union" class="headerlink" title="4.3.5.2 Union"></a>4.3.5.2 Union</h4><p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307095636.png"></p>
<p>DataStream-&gt;DataStream：对两个或者两个以上的DataStream进行union操作，产生一个包含所有DataStream元素的新DataStream,如果一条流进行union操作，则合并后的流中元素会每个都出现两次。</p>
<p>条件：当前合并的流的类型必须相同才能做union操作</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.union(otherStream1, otherStream2, ...);</span><br></pre></td></tr></table></figure>

<h2 id="4-4-Flink支持的数据类型"><a href="#4-4-Flink支持的数据类型" class="headerlink" title="4.4 Flink支持的数据类型"></a>4.4 Flink支持的数据类型</h2><p>Flink使用特有的方法控制数据类型和序列化，包含它自己的类型描述符，泛型类型的提取和序列化框架。</p>
<h3 id="4-4-1-支持的数据类型"><a href="#4-4-1-支持的数据类型" class="headerlink" title="4.4.1 支持的数据类型"></a>4.4.1 支持的数据类型</h3><p>Flink支持的数据包括以下7种数据类型：</p>
<ol>
<li>Java Tuples and Scala Case Classes(Java元组或Scala样例类)</li>
<li>Java POJOs</li>
<li>Primitive Types(原始类型)</li>
<li>Regular Classes</li>
<li>Values</li>
<li>Hadoop Writables</li>
<li>Special Types</li>
</ol>
<h3 id="4-4-2-Java-元组"><a href="#4-4-2-Java-元组" class="headerlink" title="4.4.2 Java 元组"></a>4.4.2 Java 元组</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCounts = env.fromElements(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(<span class="string">&quot;hello&quot;</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(<span class="string">&quot;world&quot;</span>, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">wordCounts.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;Tuple2&lt;String, Integer&gt;, Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(Tuple2&lt;String, Integer&gt; value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> value.f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">wordCounts.keyBy(value -&gt; value.f0);</span><br></pre></td></tr></table></figure>

<h3 id="4-4-3-POJOs"><a href="#4-4-3-POJOs" class="headerlink" title="4.4.3 POJOs"></a>4.4.3 POJOs</h3><p>如果 Java 和 Scala 类满足以下要求，Flink 会将它们视为特殊的 POJO 数据类型：</p>
<ul>
<li>类必须为public</li>
<li>必须具有public的无参构造。</li>
<li>所有字段要么是公有的，要么必须具有getter和setter方法</li>
<li>字段类型必须被已注册的序列化器支持</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordWithCount</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String word;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> count;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WordWithCount</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WordWithCount</span><span class="params">(String word, <span class="type">int</span> count)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.word = word;</span><br><span class="line">        <span class="built_in">this</span>.count = count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DataStream&lt;WordWithCount&gt; wordCounts = env.fromElements(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">WordWithCount</span>(<span class="string">&quot;hello&quot;</span>, <span class="number">1</span>),</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">WordWithCount</span>(<span class="string">&quot;world&quot;</span>, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">wordCounts.keyBy(value -&gt; value.word);</span><br></pre></td></tr></table></figure>

<h3 id="4-4-4-原始类型"><a href="#4-4-4-原始类型" class="headerlink" title="4.4.4 原始类型"></a>4.4.4 原始类型</h3><p>Flink支持所有的java和scala原始类型，例如，Integer,String,Double。</p>
<h3 id="4-4-5-其它类型"><a href="#4-4-5-其它类型" class="headerlink" title="4.4.5 其它类型"></a>4.4.5 其它类型</h3><p>Flink对Java和Scala中的一些特殊目的类型也都是支持的，比如Java的ArrayList、HashMap、Enum等等。</p>
<h2 id="4-5-实现UDF函数-更细粒度的控制流"><a href="#4-5-实现UDF函数-更细粒度的控制流" class="headerlink" title="4.5 实现UDF函数-更细粒度的控制流"></a>4.5 实现UDF函数-更细粒度的控制流</h2><h3 id="4-5-1-函数类（Function-Classes）"><a href="#4-5-1-函数类（Function-Classes）" class="headerlink" title="4.5.1 函数类（Function Classes）"></a>4.5.1 函数类（Function Classes）</h3><p>Flink 暴露了所有udf函数的接口（实现方式为接口或者抽象类）。例如MapFunction、FilterFunction、ProcessFunction等。</p>
<ol>
<li><p>实现接口</p>
<p>最基础的方法是实现提供的接口，下面以实现MapFunction为例。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyMapFunction</span> <span class="keyword">implements</span> <span class="title class_">MapFunction</span>&lt;String, Integer&gt; &#123;</span><br><span class="line">  <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(String value)</span> &#123; <span class="keyword">return</span> Integer.parseInt(value); &#125;</span><br><span class="line">&#125;;</span><br><span class="line">data.map(<span class="keyword">new</span> <span class="title class_">MyMapFunction</span>());</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过匿名类实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, Integer&gt; () &#123;</span><br><span class="line">  <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(String value)</span> &#123; <span class="keyword">return</span> Integer.parseInt(value); &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
</li>
<li><p>Java 8 Lambdas表达式</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.filter(s -&gt; s.startsWith(<span class="string">&quot;http://&quot;</span>));</span><br><span class="line">data.reduce((i1,i2) -&gt; i1 + i2);</span><br></pre></td></tr></table></figure>
</li>
<li><p>富函数</p>
<p>“富函数”是DataStream API 提供的一个函数类的接口，所有Flink函数类都有其Rich版本。它与常规函数的不同在于，可以获取运行的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。</p>
<ul>
<li><p>RichMapFunction</p>
</li>
<li><p>RichFlatMapFunction</p>
</li>
<li><p>RichFilterFunction</p>
</li>
<li><p>…</p>
<p>RichFunction有一个生命周期的概念。典型的生命周期方法有：</p>
</li>
<li><p>open()方法是rich function的初始化方法，当一个算子例如map或者filter被调用之前open()会被调用。</p>
</li>
<li><p>close()方法是生命周期中的最后一个调用方法，做一些清理工作。</p>
</li>
<li><p>getRuntimeContext()方法提供了函数的RuntimeContext的一些信息，例如函数执行的并行度，任务的名字，以及state状态等。</p>
</li>
</ul>
<p>所有需要自定义函数的转换操作可以被一个富函数进行实现，举例如下：</p>
<p>接口实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyMapFunction</span> <span class="keyword">implements</span> <span class="title class_">MapFunction</span>&lt;String, Integer&gt; &#123;</span><br><span class="line">  <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(String value)</span> &#123; <span class="keyword">return</span> Integer.parseInt(value); &#125;</span><br><span class="line">&#125;;</span><br><span class="line">data.map(<span class="keyword">new</span> <span class="title class_">MyMapFunction</span>());</span><br></pre></td></tr></table></figure>

<p>富函数实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyMapFunction</span> <span class="keyword">extends</span> <span class="title class_">RichMapFunction</span>&lt;String, Integer&gt; &#123;</span><br><span class="line">  <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(String value)</span> &#123; <span class="keyword">return</span> Integer.parseInt(value); &#125;</span><br><span class="line">&#125;;</span><br><span class="line">data.map(<span class="keyword">new</span> <span class="title class_">MyMapFunction</span>());</span><br></pre></td></tr></table></figure>

<p>富函数的匿名类实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.map (<span class="keyword">new</span> <span class="title class_">RichMapFunction</span>&lt;String, Integer&gt;() &#123;</span><br><span class="line">  <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(String value)</span> &#123; <span class="keyword">return</span> Integer.parseInt(value); &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="4-6-Sink"><a href="#4-6-Sink" class="headerlink" title="4.6 Sink"></a>4.6 Sink</h2><p>Flink没有类似于spark中foreach方法，让用户进行迭代的操作。虽有对外的输出操作都要利用Sink完成。最后通过类似如下方式完成整个任务最终输出操作。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.addSink(<span class="keyword">new</span> <span class="title class_">MySink</span>(xxxx))</span><br></pre></td></tr></table></figure>

<p>官方提供了一部分框架的sink。除此之外，需要用户自定义实现sink。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220307161040.png"></p>
<h3 id="4-6-1-kafka-Sink"><a href="#4-6-1-kafka-Sink" class="headerlink" title="4.6.1 kafka Sink"></a>4.6.1 kafka Sink</h3><p>引入maven配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-connector-kafka_2<span class="number">.11</span>&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">1.14</span><span class="number">.3</span>&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>



<p>Kafka sink 提供一个构造器实现KafkaSink实例，下面是一个实例，并能保证最少一次交付。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.sink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SerializationSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.KafkaSerializationSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Nullable;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/30</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 19:16</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SinkTestKafka</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="comment">//1.创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//2.选择数据源</span></span><br><span class="line">        DataStreamSource&lt;String&gt; inputStream = env.readTextFile(<span class="string">&quot;F:\\Program\\FlinkProgram\\src\\main\\resources\\sensor.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 转换成SensorReading类型</span></span><br><span class="line">        DataStream&lt;String&gt; streamOperator = inputStream.map(line -&gt; &#123;</span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SensorReading</span>(fields[<span class="number">0</span>], <span class="keyword">new</span> <span class="title class_">Long</span>(fields[<span class="number">1</span>]), <span class="keyword">new</span> <span class="title class_">Double</span>(fields[<span class="number">2</span>])).toString();</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 方式1：添加到kafka sink,使用addSink添加</span></span><br><span class="line">        <span class="comment">//streamOperator.addSink(new FlinkKafkaProducer&lt;String&gt;(&quot;localhost:9092&quot;, &quot;sinkTest&quot;, new SimpleStringSchema()));</span></span><br><span class="line">        <span class="comment">// 方式2：添加到kafka sink, 使用addSink添加</span></span><br><span class="line">        <span class="comment">//streamOperator.addSink(MySink.myKafkaSink());</span></span><br><span class="line">        streamOperator.addSink(kafkaSink());</span><br><span class="line">        <span class="comment">//5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span>  FlinkKafkaProducer <span class="title function_">kafkaSink</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.setProperty(<span class="string">&quot;bootstrap.server&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">        FlinkKafkaProducer&lt;String&gt; producer = <span class="keyword">new</span> <span class="title class_">FlinkKafkaProducer</span>&lt;String&gt;(<span class="string">&quot;my-topic&quot;</span>,<span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>(),properties);</span><br><span class="line">        <span class="keyword">return</span> producer ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-6-2-Redis-Sink"><a href="#4-6-2-Redis-Sink" class="headerlink" title="4.6.2 Redis Sink"></a>4.6.2 Redis Sink</h3><p>引入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.bahir/flink-connector-redis --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.bahir<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-redis_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>方法实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.sink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.redis.common.config.FlinkJedisPoolConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.redis.common.mapper.RedisCommand;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.redis.common.mapper.RedisCommandDescription;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.redis.common.mapper.RedisMapper;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2021/11/30</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 20:29</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SinkTestRedis</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//1.创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//2.选择数据源</span></span><br><span class="line">        DataStreamSource&lt;String&gt; inputStream = env.readTextFile(<span class="string">&quot;F:\\Program\\FlinkProgram\\src\\main\\resources\\sensor.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 转换成SensorReading类型</span></span><br><span class="line">        DataStream&lt;SensorReading&gt; streamOperator = inputStream.map(line -&gt; &#123;</span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SensorReading</span>(fields[<span class="number">0</span>], <span class="keyword">new</span> <span class="title class_">Long</span>(fields[<span class="number">1</span>]), <span class="keyword">new</span> <span class="title class_">Double</span>(fields[<span class="number">2</span>]));</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.Redis Sink</span></span><br><span class="line">        <span class="type">FlinkJedisPoolConfig</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlinkJedisPoolConfig</span>.Builder()</span><br><span class="line">                .setHost(<span class="string">&quot;localhost&quot;</span>)</span><br><span class="line">                .setPort(<span class="number">6379</span>)</span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        streamOperator.addSink(<span class="keyword">new</span> <span class="title class_">RedisSink</span>&lt;&gt;(config, <span class="keyword">new</span> <span class="title class_">MyRedisMapper</span>()));</span><br><span class="line">        <span class="comment">//streamOperator.addSink(MySink.myRedisSink(&quot;localhost&quot;,6667));</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 自定义RedisMapper</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyRedisMapper</span> <span class="keyword">implements</span> <span class="title class_">RedisMapper</span>&lt;SensorReading&gt;&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 定义保存数据到redis的命令，存成Hash表，hset sensor_tamp</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> RedisCommandDescription <span class="title function_">getCommandDescription</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RedisCommandDescription</span>(RedisCommand.HSET,<span class="string">&quot;sensor_tamp&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> String <span class="title function_">getKeyFromData</span><span class="params">(SensorReading data)</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> data.getId();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> String <span class="title function_">getValueFromData</span><span class="params">(SensorReading data)</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> data.getTemperature().toString();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-6-3-JDBC-Sink"><a href="#4-6-3-JDBC-Sink" class="headerlink" title="4.6.3 JDBC Sink"></a>4.6.3 JDBC Sink</h3><p>添加依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.14.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>代码实现：</p>
<p>JDBC Sink 连接器提供至少一次安全保证，虽然如此，可以通过制作 upsert SQL 语句或幂等 SQL 更新来实现恰好一次。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JdbcSink.sink(</span><br><span class="line">      	sqlDmlStatement,                       <span class="comment">// mandatory</span></span><br><span class="line">      	jdbcStatementBuilder,                  <span class="comment">// mandatory   	</span></span><br><span class="line">      	jdbcExecutionOptions,                  <span class="comment">// optional</span></span><br><span class="line">      	jdbcConnectionOptions                  <span class="comment">// mandatory</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>上面代码中，四个参数如下：</p>
<ol>
<li><p>sqlDmlStatement</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> some_table field1, field2 <span class="keyword">values</span> (?, ?)</span><br></pre></td></tr></table></figure>
</li>
<li><p>jdbcStatementBuilder</p>
<p>SQL DML 语句和 POJO对象的对应关系。</p>
</li>
<li><p>jdbcExecutionOptions</p>
<p>若想让SQL DML语句批量执行，可以通过配置如下参数实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">JdbcExecutionOptions.builder()</span><br><span class="line">        .withBatchIntervalMs(<span class="number">200</span>)             <span class="comment">// optional: default = 0, meaning no time-based execution is done</span></span><br><span class="line">        .withBatchSize(<span class="number">1000</span>)                  <span class="comment">// optional: default = 5000 values</span></span><br><span class="line">        .withMaxRetries(<span class="number">5</span>)                    <span class="comment">// optional: default = 3 </span></span><br><span class="line">.build()</span><br></pre></td></tr></table></figure>

<p>只要满足以下三个条件之一就会实现SQL批量插入数据。</p>
<ul>
<li>达到配置的批处理执行时间</li>
<li>达到配置的最大批处理执行数据量</li>
<li>Flink的checkpoint 已经启动</li>
</ul>
</li>
<li><p>JDBC connection parameters</p>
<p>与数据库的连接实例配置，用户名、数据库名、密码等参数。</p>
</li>
</ol>
<p>下面是一个完整的JDBC Sink实例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.sink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcConnectionOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcExecutionOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcSink;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2022/3/8</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 15:53</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JdbcSinkExample</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Book</span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Long id;</span><br><span class="line">        <span class="keyword">final</span> String title;</span><br><span class="line">        <span class="keyword">final</span> String authors;</span><br><span class="line">        <span class="keyword">final</span> Integer year;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">Book</span><span class="params">(Long id, String title, String authors, Integer year)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.id = id;</span><br><span class="line">            <span class="built_in">this</span>.title = title;</span><br><span class="line">            <span class="built_in">this</span>.authors = authors;</span><br><span class="line">            <span class="built_in">this</span>.year = year;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment</span><br><span class="line">                .getExecutionEnvironment()</span><br><span class="line">                .setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//添加数据源</span></span><br><span class="line">        DataStreamSource&lt;Book&gt; streamSource = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Book</span>(<span class="number">101L</span>, <span class="string">&quot;Stream Processing with Apache Flink&quot;</span>, <span class="string">&quot;Fabian Hueske, Vasiliki Kalavri&quot;</span>, <span class="number">2019</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Book</span>(<span class="number">102L</span>, <span class="string">&quot;Streaming Systems&quot;</span>, <span class="string">&quot;Tyler Akidau, Slava Chernyak, Reuven Lax&quot;</span>, <span class="number">2018</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Book</span>(<span class="number">103L</span>, <span class="string">&quot;Designing Data-Intensive Applications&quot;</span>, <span class="string">&quot;Martin Kleppmann&quot;</span>, <span class="number">2017</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Book</span>(<span class="number">104L</span>, <span class="string">&quot;Kafka: The Definitive Guide&quot;</span>, <span class="string">&quot;Gwen Shapira, Neha Narkhede, Todd Palino&quot;</span>, <span class="number">2017</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//JDBC Sink</span></span><br><span class="line">        streamSource.addSink(JdbcSink.sink(</span><br><span class="line">                <span class="string">&quot;insert into books (id, title, authors, year) values (?, ?, ?, ?)&quot;</span>,</span><br><span class="line">                (preparedStatement, book) -&gt; &#123;</span><br><span class="line">                    preparedStatement.setLong(<span class="number">1</span>,book.id);</span><br><span class="line">                    preparedStatement.setString(<span class="number">2</span>, book.title);</span><br><span class="line">                    preparedStatement.setString(<span class="number">3</span>, book.authors);</span><br><span class="line">                    preparedStatement.setInt(<span class="number">4</span>, book.year);&#125;,</span><br><span class="line">                JdbcExecutionOptions.builder()</span><br><span class="line">                        .withBatchSize(<span class="number">1000</span>)</span><br><span class="line">                        .withBatchIntervalMs(<span class="number">200</span>)</span><br><span class="line">                        .withMaxRetries(<span class="number">5</span>)</span><br><span class="line">                        .build(),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">JdbcConnectionOptions</span>.JdbcConnectionOptionsBuilder()</span><br><span class="line">                        .withUrl(<span class="string">&quot;jdbc:postgresql://dbhost:5432/postgresdb&quot;</span>)</span><br><span class="line">                        .withDriverName(<span class="string">&quot;org.postgresql.Driver&quot;</span>)</span><br><span class="line">                        .withUsername(<span class="string">&quot;someuser&quot;</span>)</span><br><span class="line">                        .withPassword(<span class="string">&quot;password&quot;</span>)</span><br><span class="line">                        .build()</span><br><span class="line"></span><br><span class="line">        ));</span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从Flink 1.13开始，JDBC Sink 支持 exactly-once (恰好一次交付)模式，实现依赖于数据库是否支持 XA模式。</p>
<p>如果想使用恰好一次交付模式，使用 exactlyOnceSink()来创建JDBC sink，需要提供的参数包括以下三个。</p>
<ol>
<li>exactly-once options</li>
<li>execution options</li>
<li>XA DataSource Supplier</li>
</ol>
<p>举例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env</span><br><span class="line">        .fromElements(...)</span><br><span class="line">        .addSink(JdbcSink.exactlyOnceSink(</span><br><span class="line">                <span class="string">&quot;insert into books (id, title, author, price, qty) values (?,?,?,?,?)&quot;</span>,</span><br><span class="line">                (ps, t) -&gt; &#123;</span><br><span class="line">                    ps.setInt(<span class="number">1</span>, t.id);</span><br><span class="line">                    ps.setString(<span class="number">2</span>, t.title);</span><br><span class="line">                    ps.setString(<span class="number">3</span>, t.author);</span><br><span class="line">                    ps.setDouble(<span class="number">4</span>, t.price);</span><br><span class="line">                    ps.setInt(<span class="number">5</span>, t.qty);</span><br><span class="line">                &#125;,</span><br><span class="line">                JdbcExecutionOptions.builder()</span><br><span class="line">                    .withMaxRetries(<span class="number">0</span>)</span><br><span class="line">                    .build(),</span><br><span class="line">                JdbcExactlyOnceOptions.defaults(),</span><br><span class="line">                () -&gt; &#123;</span><br><span class="line">                    <span class="comment">// create a driver-specific XA DataSource</span></span><br><span class="line">                    <span class="comment">// The following example is for derby </span></span><br><span class="line">                    <span class="type">EmbeddedXADataSource</span> <span class="variable">ds</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">EmbeddedXADataSource</span>();</span><br><span class="line">                    ds.setDatabaseName(<span class="string">&quot;my_db&quot;</span>);</span><br><span class="line">                    <span class="keyword">return</span> ds;</span><br><span class="line">                &#125;);</span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

<h1 id="5-Flink-Window-API"><a href="#5-Flink-Window-API" class="headerlink" title="5 Flink Window API"></a>5 Flink Window API</h1><p>Windows是Flink处理无界流的核心。Windows将流拆分成有限大小的桶，在此之上进行应用计算。</p>
<p>一个通用的开窗后的Flink程序如下特点：</p>
<ol>
<li>开窗可以针对keyed Stream或者是non-keyed Stream。</li>
<li>对于keyed Stream 一般先通过 <code>keyBy()</code> 分组后调用 <code>window()</code>进行开窗，而non-keyed Stream直接调用 <code>windowAll()</code> 进行开窗。</li>
</ol>
<p>Keyed Windows 代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">       .keyBy(...)               &lt;-  keyed versus non-keyed windows</span><br><span class="line">       .window(...)              &lt;-  required: <span class="string">&quot;assigner&quot;</span></span><br><span class="line">      [.trigger(...)]            &lt;-  optional: <span class="string">&quot;trigger&quot;</span> (<span class="keyword">else</span> <span class="keyword">default</span> trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  optional: <span class="string">&quot;evictor&quot;</span> (<span class="keyword">else</span> no evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  optional: <span class="string">&quot;lateness&quot;</span> (<span class="keyword">else</span> zero)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  optional: <span class="string">&quot;output tag&quot;</span> (<span class="keyword">else</span> no side output <span class="keyword">for</span> late data)</span><br><span class="line">       .reduce/aggregate/apply()      &lt;-  required: <span class="string">&quot;function&quot;</span></span><br><span class="line">      [.getSideOutput(...)]      &lt;-  optional: <span class="string">&quot;output tag&quot;</span></span><br></pre></td></tr></table></figure>

<p>non-Keyed Windows</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">       .windowAll(...)           &lt;-  required: <span class="string">&quot;assigner&quot;</span></span><br><span class="line">      [.trigger(...)]            &lt;-  optional: <span class="string">&quot;trigger&quot;</span> (<span class="keyword">else</span> <span class="keyword">default</span> trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  optional: <span class="string">&quot;evictor&quot;</span> (<span class="keyword">else</span> no evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  optional: <span class="string">&quot;lateness&quot;</span> (<span class="keyword">else</span> zero)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  optional: <span class="string">&quot;output tag&quot;</span> (<span class="keyword">else</span> no side output <span class="keyword">for</span> late data)</span><br><span class="line">       .reduce/aggregate/apply()      &lt;-  required: <span class="string">&quot;function&quot;</span></span><br><span class="line">      [.getSideOutput(...)]      &lt;-  optional: <span class="string">&quot;output tag&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="5-1-Window-的生命周期"><a href="#5-1-Window-的生命周期" class="headerlink" title="5.1 Window 的生命周期"></a>5.1 Window 的生命周期</h2><p>从属于该窗口的第一个元素到达就会创建一个窗口，当时间（事件或处理时间）超过其结束时间戳加上用户指定的允许延迟时，窗口将被完全删除。例如使用基于时间的窗口策略每5分钟创建一个non-overlapping(不重叠)或者tumping(滚动窗口)并且允许延迟1分钟，flink将会在12：00-12：05间隔内第一个元素到来时创建一个窗口，并且在12：06的时候窗口关闭。</p>
<p>另外，每一个窗口都会有一个触发器和一个函数（ProcessWindowFunction，ReduceFunction, AggregateFunction），函数用于窗口内的内容计算，触发器用于指定用于窗口计算的条件。</p>
<h2 id="5-2-Flink-中常见的窗口"><a href="#5-2-Flink-中常见的窗口" class="headerlink" title="5.2 Flink 中常见的窗口"></a>5.2 Flink 中常见的窗口</h2><p>Flink 中常见的窗口有如下几种：</p>
<ol>
<li>滚动窗口（tumbling windows）</li>
<li>滑动窗口（sliding windows）</li>
<li>会话窗口（session windows）</li>
<li>全局窗口（global windows）</li>
</ol>
<p>Flink还支持通过继承 WindowAssigner Class来实现用户自定义窗口分配器，出了全局窗口以外，所有的窗口都是基于时间进行窗口分配的，这个时间可以是处理时间，也可以是事件时间。</p>
<h2 id="5-3-滚动窗口"><a href="#5-3-滚动窗口" class="headerlink" title="5.3 滚动窗口"></a>5.3 滚动窗口</h2><p>滚动窗口的大小由用户指定，滚动窗口之间没有重叠。例如指定了一个5分钟的滚动窗口,每5分钟便会启动一个新的窗口。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309113845.png"></p>
<p>滚动窗口的代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// tumbling event-time windows</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// tumbling processing-time windows</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingProcessingTimeWindows.of(Time.seconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// daily tumbling event-time windows offset by -8 hours.</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Time.days(<span class="number">1</span>), Time.hours(-<span class="number">8</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure>

<p>可以通过设置偏移量，来改变时区。例如东八区一般设置成 <code>Time.hours(-8)</code></p>
<h2 id="5-4-滑动窗口"><a href="#5-4-滑动窗口" class="headerlink" title="5.4 滑动窗口"></a>5.4 滑动窗口</h2><p>滑动窗口和滚动窗口类似，同样有固定的窗口大小，窗口的大小由参数指定，另外窗口的滑动大小也是由参数指定，当滑动窗口的滑动大小&lt;窗口大小时，滑动窗口会发生重叠，在这种情况下，一个元素可能会属于多个窗口。</p>
<p>下面是一个窗口大小为10分钟，滑动大小为5分钟的窗口。每5分钟产生一个大小为10分钟的窗口，该窗口包含最近10分钟内的所有元素。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309150909.png"></p>
<p>下面是滑动窗口的实现代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// sliding event-time windows</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(SlidingEventTimeWindows.of(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// sliding processing-time windows</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(SlidingProcessingTimeWindows.of(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// sliding processing-time windows offset by -8 hours</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(SlidingProcessingTimeWindows.of(Time.hours(<span class="number">12</span>), Time.hours(<span class="number">1</span>), Time.hours(-<span class="number">8</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure>

<h2 id="5-5-会话窗口"><a href="#5-5-会话窗口" class="headerlink" title="5.5 会话窗口"></a>5.5 会话窗口</h2><p>会话窗口按照会话活动分配窗口，会话窗口不覆盖并且没有固定的开始和结束时间。与滑动窗口和滚动窗口相比，会话窗口会在一段时间内接收不到数据后自动关闭。会话窗口可以定义窗口关闭的间隙，当这个窗口间隙到来，旧的窗口关闭，产生一个新的窗口。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309161236.png"></p>
<p>会话窗口代码实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// event-time session windows with static gap</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withGap(Time.minutes(<span class="number">10</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line">    </span><br><span class="line"><span class="comment">// event-time session windows with dynamic gap</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withDynamicGap((element) -&gt; &#123;</span><br><span class="line">        <span class="comment">// determine and return session gap</span></span><br><span class="line">    &#125;))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// processing-time session windows with static gap</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(ProcessingTimeSessionWindows.withGap(Time.minutes(<span class="number">10</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line">    </span><br><span class="line"><span class="comment">// processing-time session windows with dynamic gap</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(ProcessingTimeSessionWindows.withDynamicGap((element) -&gt; &#123;</span><br><span class="line">        <span class="comment">// determine and return session gap</span></span><br><span class="line">    &#125;))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure>

<h2 id="5-6-全局窗口"><a href="#5-6-全局窗口" class="headerlink" title="5.6 全局窗口"></a>5.6 全局窗口</h2><p>全局窗口会将具有相同键的所有元素分配到一个全局窗口，只有指定用户触发器的时候全局窗口才会生效，否则窗口不会执行任何计算。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220309162652.png"></p>
<p>全局窗口代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(GlobalWindows.create())</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure>

<h2 id="5-7-窗口函数"><a href="#5-7-窗口函数" class="headerlink" title="5.7 窗口函数"></a>5.7 窗口函数</h2><p>指定完窗口以后，我们需要指定在定义的窗口内部做哪些计算，窗口函数可以是 <code>ReduceFunction</code> 、<code>AggregateFunction</code> 、 <code>ProcessWindowFunction</code> ，前两个函数执行起来更高效，因为Flink可以对到达的元素进行增量聚合。</p>
<h3 id="5-7-1-Reduce-Function"><a href="#5-7-1-Reduce-Function" class="headerlink" title="5.7.1 Reduce Function"></a>5.7.1 Reduce Function</h3><p>Reduce Function 用来将两个输入数据根据某种计算联合成一个元素进行输出。Flink通过 ReduceFunction增量聚合窗口中的数据。</p>
<p>示例代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(&lt;window assigner&gt;)</span><br><span class="line">    .reduce(<span class="keyword">new</span> <span class="title class_">ReduceFunction</span>&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">      <span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title function_">reduce</span><span class="params">(Tuple2&lt;String, Long&gt; v1, Tuple2&lt;String, Long&gt; v2)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(v1.f0, v1.f1 + v2.f1);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>

<h3 id="5-7-2-Aggregate-Function"><a href="#5-7-2-Aggregate-Function" class="headerlink" title="5.7.2 Aggregate Function"></a>5.7.2 Aggregate Function</h3><p>AggregateFunction 是ReduceFunction的一般形式，具有三种类型：输入类型 (IN)、累加器类型 (ACC) 和输出类型 (OUT)。 输入类型是输入流中元素的类型，并且 AggregateFunction 具有将一个输入元素添加到累加器的方法。 该接口还具有用于创建初始累加器、将两个累加器合并为一个累加器以及从累加器中提取输出（OUT 类型）的方法。</p>
<p>java代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The accumulator is used to keep a running sum and a count. The &#123;<span class="doctag">@code</span> getResult&#125; method</span></span><br><span class="line"><span class="comment"> * computes the average.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AverageAggregate</span></span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">AggregateFunction</span>&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;Long, Long&gt;, Double&gt; &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">createAccumulator</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="number">0L</span>, <span class="number">0L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">add</span><span class="params">(Tuple2&lt;String, Long&gt; value, Tuple2&lt;Long, Long&gt; accumulator)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(accumulator.f0 + value.f1, accumulator.f1 + <span class="number">1L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Double <span class="title function_">getResult</span><span class="params">(Tuple2&lt;Long, Long&gt; accumulator)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> ((<span class="type">double</span>) accumulator.f0) / accumulator.f1;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">merge</span><span class="params">(Tuple2&lt;Long, Long&gt; a, Tuple2&lt;Long, Long&gt; b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(a.f0 + b.f0, a.f1 + b.f1);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(&lt;window assigner&gt;)</span><br><span class="line">    .aggregate(<span class="keyword">new</span> <span class="title class_">AverageAggregate</span>());</span><br></pre></td></tr></table></figure>

<h3 id="5-7-3-ProcessWindowFunction"><a href="#5-7-3-ProcessWindowFunction" class="headerlink" title="5.7.3 ProcessWindowFunction"></a>5.7.3 ProcessWindowFunction</h3><p>ProcessWindowFunction 获得一个包含窗口所有元素的 Iterable，以及一个可以访问时间和状态信息的 Context 对象，这使得它能够提供比其他窗口函数更大的灵活性。 这是以性能和资源消耗为代价的，因为元素不能增量聚合，而是需要在内部缓冲，直到窗口被认为准备好处理。</p>
<p>ProcessWindowFunction 代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ssWindowFunction </span><br><span class="line">    <span class="keyword">extends</span> <span class="title class_">ProcessWindowFunction</span>&lt;Tuple2&lt;String, Long&gt;, String, String, TimeWindow&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(String key, Context context, Iterable&lt;Tuple2&lt;String, Long&gt;&gt; input, Collector&lt;String&gt; out)</span> &#123;</span><br><span class="line">    <span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (Tuple2&lt;String, Long&gt; in: input) &#123;</span><br><span class="line">      count++;</span><br><span class="line">    &#125;</span><br><span class="line">    out.collect(<span class="string">&quot;Window: &quot;</span> + context.window() + <span class="string">&quot;count: &quot;</span> + count);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-7-4-具有增量聚合的ProcessWindowFunction"><a href="#5-7-4-具有增量聚合的ProcessWindowFunction" class="headerlink" title="5.7.4 具有增量聚合的ProcessWindowFunction"></a>5.7.4 具有增量聚合的ProcessWindowFunction</h3><p>ProcessWindowFunction 可以结合一个 ReduceFunction或AggregateFunction对窗口内数据实现增量聚合，窗口关闭的时候，ProcessWindowFunction要给出增量聚合的结果。</p>
<p>也可以使用旧版的WindowFunction代替ProcessWindowFunction实现增量聚合。</p>
<p>通过结合ReduceFunction实现增量聚合的代码如下，该代码返回窗口的最小事件以及窗口的开始时间。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;SensorReading&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">  .keyBy(&lt;key selector&gt;)</span><br><span class="line">  .window(&lt;window assigner&gt;)</span><br><span class="line">  .reduce(<span class="keyword">new</span> <span class="title class_">MyReduceFunction</span>(), <span class="keyword">new</span> <span class="title class_">MyProcessWindowFunction</span>());</span><br><span class="line"></span><br><span class="line"><span class="comment">// Function definitions</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyReduceFunction</span> <span class="keyword">implements</span> <span class="title class_">ReduceFunction</span>&lt;SensorReading&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> SensorReading <span class="title function_">reduce</span><span class="params">(SensorReading r1, SensorReading r2)</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> r1.value() &gt; r2.value() ? r2 : r1;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyProcessWindowFunction</span></span><br><span class="line">    <span class="keyword">extends</span> <span class="title class_">ProcessWindowFunction</span>&lt;SensorReading, Tuple2&lt;Long, SensorReading&gt;, String, TimeWindow&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(String key,</span></span><br><span class="line"><span class="params">                    Context context,</span></span><br><span class="line"><span class="params">                    Iterable&lt;SensorReading&gt; minReadings,</span></span><br><span class="line"><span class="params">                    Collector&lt;Tuple2&lt;Long, SensorReading&gt;&gt; out)</span> &#123;</span><br><span class="line">      <span class="type">SensorReading</span> <span class="variable">min</span> <span class="operator">=</span> minReadings.iterator().next();</span><br><span class="line">      out.collect(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Long, SensorReading&gt;(context.window().getStart(), min));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过AggregateFunction结合实现计算平均值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">  .keyBy(&lt;key selector&gt;)</span><br><span class="line">  .window(&lt;window assigner&gt;)</span><br><span class="line">  .aggregate(<span class="keyword">new</span> <span class="title class_">AverageAggregate</span>(), <span class="keyword">new</span> <span class="title class_">MyProcessWindowFunction</span>());</span><br><span class="line"></span><br><span class="line"><span class="comment">// Function definitions</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The accumulator is used to keep a running sum and a count. The &#123;<span class="doctag">@code</span> getResult&#125; method</span></span><br><span class="line"><span class="comment"> * computes the average.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AverageAggregate</span></span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">AggregateFunction</span>&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;Long, Long&gt;, Double&gt; &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">createAccumulator</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="number">0L</span>, <span class="number">0L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">add</span><span class="params">(Tuple2&lt;String, Long&gt; value, Tuple2&lt;Long, Long&gt; accumulator)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(accumulator.f0 + value.f1, accumulator.f1 + <span class="number">1L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Double <span class="title function_">getResult</span><span class="params">(Tuple2&lt;Long, Long&gt; accumulator)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> ((<span class="type">double</span>) accumulator.f0) / accumulator.f1;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">merge</span><span class="params">(Tuple2&lt;Long, Long&gt; a, Tuple2&lt;Long, Long&gt; b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(a.f0 + b.f0, a.f1 + b.f1);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyProcessWindowFunction</span></span><br><span class="line">    <span class="keyword">extends</span> <span class="title class_">ProcessWindowFunction</span>&lt;Double, Tuple2&lt;String, Double&gt;, String, TimeWindow&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(String key,</span></span><br><span class="line"><span class="params">                    Context context,</span></span><br><span class="line"><span class="params">                    Iterable&lt;Double&gt; averages,</span></span><br><span class="line"><span class="params">                    Collector&lt;Tuple2&lt;String, Double&gt;&gt; out)</span> &#123;</span><br><span class="line">      <span class="type">Double</span> <span class="variable">average</span> <span class="operator">=</span> averages.iterator().next();</span><br><span class="line">      out.collect(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(key, average));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-7-5-触发器"><a href="#5-7-5-触发器" class="headerlink" title="5.7.5 触发器"></a>5.7.5 触发器</h3><p>每个窗口分配器都有一个默认的窗口触发器。如果默认触发器不满足你的需求，可以通过 <code>trigger(...)</code> 自定义触发器。</p>
<p>默认有五种事件触发器：</p>
<ol>
<li><code>onElement()</code> 每个元素添加到窗口时触发</li>
<li><code>onEventTime</code> 事件触发</li>
<li><code>onProcessingTime()</code> </li>
<li><code>onMerge()</code></li>
<li><code>clear()</code></li>
</ol>
<h3 id="5-7-6-移除器"><a href="#5-7-6-移除器" class="headerlink" title="5.7.6 移除器"></a>5.7.6 移除器</h3><p><code>evictor()</code> 定义移除某些数据逻辑</p>
<h3 id="5-7-7-允许处理迟到的数据"><a href="#5-7-7-允许处理迟到的数据" class="headerlink" title="5.7.7 允许处理迟到的数据"></a>5.7.7 允许处理迟到的数据</h3><p><code>allowedLateness()</code></p>
<h3 id="5-7-8-将迟到的数据放入侧输出流"><a href="#5-7-8-将迟到的数据放入侧输出流" class="headerlink" title="5.7.8 将迟到的数据放入侧输出流"></a>5.7.8 将迟到的数据放入侧输出流</h3><p><code>sideOutputLateData()</code></p>
<h3 id="5-7-9-获取侧输出流"><a href="#5-7-9-获取侧输出流" class="headerlink" title="5.7.9 获取侧输出流"></a>5.7.9 获取侧输出流</h3><p><code>getSideOutput()</code></p>
<h1 id="6-时间语义和-watermark"><a href="#6-时间语义和-watermark" class="headerlink" title="6 时间语义和 watermark"></a>6 时间语义和 watermark</h1><h2 id="6-1-时间语义"><a href="#6-1-时间语义" class="headerlink" title="6.1 时间语义"></a>6.1 时间语义</h2><p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220310151305.png"></p>
<ul>
<li>Event Time: 事件创建的时间，一般由数据产生的时间戳决定，跟任何时钟无关。事件时间一般更常用。</li>
<li>Processing Time: 执行操作算子的本地系统时间，与机器相关。</li>
</ul>
<p>代码中如果不做说明，默认的是Processing Time。</p>
<h2 id="6-2-Event-Time和Watermarks"><a href="#6-2-Event-Time和Watermarks" class="headerlink" title="6.2 Event Time和Watermarks"></a>6.2 Event Time和Watermarks</h2><p>Flink 衡量事件时间进展的机制是Watermarks，watermarks作为作为数据流的一部分且带有时间戳。watermark(t)代表的是t时刻的事件时间已经进入流中，意味着小于t时刻的数据均已进入流中。</p>
<ol>
<li>watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用watermark机制结合window来实现。</li>
<li>watermark可以认为表被拨慢了t。</li>
<li>watermark用来让程序自己平衡延迟和结果正确性。</li>
</ol>
<p>对于时间有序的流watermarks只是一个周期性的标记，如下图所示</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220310163815.png"></p>
<p>watermarks对于乱序流更为关键，遇到了一个时间戳到达了窗口关闭时间，不应该立即触发窗口计算，而是等待一段时间，等迟到的数据来了再关闭窗口进行计算。</p>
<p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220310164149.png"></p>
<p><strong>watermark的特点：</strong></p>
<ul>
<li>watermark是一条特殊的数据记录</li>
<li>watermark必须单调递增，以确保任务的事件时间时钟在向前推动，而不是向后退</li>
<li>watermark与数据的时间戳相关</li>
</ul>
<h2 id="6-3-watermark的传递"><a href="#6-3-watermark的传递" class="headerlink" title="6.3 watermark的传递"></a>6.3 watermark的传递</h2><p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220311093501.png"></p>
<h2 id="6-4-watermark代码案例"><a href="#6-4-watermark代码案例" class="headerlink" title="6.4 watermark代码案例"></a>6.4 watermark代码案例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.tj712.apitest.window;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.tj712.apitest.beans.SensorReading;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Date</span>: 2022/3/11</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Time</span>: 10:32</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: ThinkPad</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestWatermarks</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">environment</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        environment.setParallelism(<span class="number">1</span>);</span><br><span class="line">        environment.getConfig().setAutoWatermarkInterval(<span class="number">100</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; inputStream = environment.socketTextStream(<span class="string">&quot;localhost&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//转换成SensorReading类型,设置了watermark</span></span><br><span class="line">        SingleOutputStreamOperator&lt;SensorReading&gt; dataStream = inputStream.map(line -&gt; &#123;</span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SensorReading</span>(fields[<span class="number">0</span>], <span class="keyword">new</span> <span class="title class_">Long</span>(fields[<span class="number">1</span>]), <span class="keyword">new</span> <span class="title class_">Double</span>(fields[<span class="number">2</span>]));</span><br><span class="line">        &#125;).assignTimestampsAndWatermarks(<span class="keyword">new</span> <span class="title class_">BoundedOutOfOrdernessTimestampExtractor</span>&lt;SensorReading&gt;(Time.seconds(<span class="number">2</span>)) &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">extractTimestamp</span><span class="params">(SensorReading element)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> element.getTimestamp() * <span class="number">1000L</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//基于事件时间的开窗聚合，统计15秒内温度的最小值</span></span><br><span class="line">        SingleOutputStreamOperator&lt;SensorReading&gt; minTempStream = dataStream.keyBy(SensorReading::getId)</span><br><span class="line">                .window(TumblingProcessingTimeWindows.of(Time.seconds(<span class="number">15</span>)))</span><br><span class="line">                .minBy(<span class="string">&quot;temperature&quot;</span>);</span><br><span class="line"></span><br><span class="line">        minTempStream.print(<span class="string">&quot;minTemp&quot;</span>);</span><br><span class="line">        environment.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="7-Flink-状态管理"><a href="#7-Flink-状态管理" class="headerlink" title="7 Flink 状态管理"></a>7 Flink 状态管理</h1><ul>
<li>Flink中的状态</li>
<li>算子状态（Operatior State）</li>
<li>键控状态（Keyed State）</li>
<li>状态后端（State Backends）</li>
</ul>
<h2 id="7-1-Flink中的状态"><a href="#7-1-Flink中的状态" class="headerlink" title="7.1 Flink中的状态"></a>7.1 Flink中的状态</h2><p><img src="https://raw.githubusercontent.com/yimisiyang/cloudimage/master/Image/20220311151027.png"></p>
<ol>
<li>由一个任务维护，并且用来计算某个结果的所有数据，都属于这个任务的状态</li>
<li>可以认为状态就是一个本地变量，可以被任务的业务逻辑访问</li>
<li>Flink会进行状态管理，包括状态一致性、故障处理以及高效存储和访问，以便开发人员可以专注于应用程序的逻辑</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/gitblog/2022/04/04/%E5%B7%A5%E5%85%B7/Git&GitHub%E6%95%99%E7%A8%8B/" rel="prev" title="">
      <i class="fa fa-chevron-left"></i> 
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Flink%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">1 Flink概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-Flink%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 Flink主要特点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Flink-%E9%83%A8%E7%BD%B2"><span class="nav-number">2.</span> <span class="nav-text">2 Flink 部署</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Standalone%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 Standalone模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Yarn%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 Yarn模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-Flink-on-Yarn"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1 Flink on Yarn</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-Session-Cluster-%E6%A8%A1%E5%BC%8F%E5%90%AF%E5%8A%A8"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2 Session Cluster 模式启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-3-Per-Job-Cluster-%E6%A8%A1%E5%BC%8F%E5%90%AF%E5%8A%A8"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.2.3 Per Job Cluster 模式启动</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Kubernetes%E9%83%A8%E7%BD%B2"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 Kubernetes部署</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Flink-%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text">3 Flink 运行架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Flink%E8%BF%90%E8%A1%8C%E6%97%B6%E7%9A%84%E7%BB%84%E4%BB%B6"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Flink运行时的组件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 任务提交流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 任务调度原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-1-%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="nav-number">3.3.1.</span> <span class="nav-text">3.3.1 并行度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-2-%E7%A8%8B%E5%BA%8F%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B5%81%EF%BC%88DataFlow%EF%BC%89"><span class="nav-number">3.3.2.</span> <span class="nav-text">3.3.2 程序与数据流（DataFlow）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Flink%E6%B5%81%E5%A4%84%E7%90%86API"><span class="nav-number">4.</span> <span class="nav-text">4 Flink流处理API</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E5%88%9B%E5%BB%BA%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 创建执行环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 读取数据源</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-%E4%BB%8E%E9%9B%86%E5%90%88%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1 从集合读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-%E4%BB%8E%E6%96%87%E6%9C%AC%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">4.2.2.</span> <span class="nav-text">4.2.2 从文本中读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-%E4%BB%8Esocket%E6%B5%81%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">4.2.3.</span> <span class="nav-text">4.2.3 从socket流中读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-4-%E4%BB%8Ekafka%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">4.2.4.</span> <span class="nav-text">4.2.4 从kafka中读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-5-%E4%BB%8ERabbitMQ%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="nav-number">4.2.5.</span> <span class="nav-text">4.2.5 从RabbitMQ中读取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-6-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="nav-number">4.2.6.</span> <span class="nav-text">4.2.6 自定义数据源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 转换算子</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-1-map%E7%AE%97%E5%AD%90"><span class="nav-number">4.3.1.</span> <span class="nav-text">4.3.1 map算子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-FlatMap-%E7%AE%97%E5%AD%90"><span class="nav-number">4.3.2.</span> <span class="nav-text">4.3.2  FlatMap 算子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-3-Filter-%E7%AE%97%E5%AD%90"><span class="nav-number">4.3.3.</span> <span class="nav-text">4.3.3 Filter 算子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-4-KeyBy%E7%AE%97%E5%AD%90"><span class="nav-number">4.3.4.</span> <span class="nav-text">4.3.4 KeyBy算子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-4-1-%E6%BB%9A%E5%8A%A8%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90%EF%BC%88Rolling-Aggregation%EF%BC%89"><span class="nav-number">4.3.4.1.</span> <span class="nav-text">4.3.4.1 滚动聚合算子（Rolling Aggregation）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-4-2-Reduce"><span class="nav-number">4.3.4.2.</span> <span class="nav-text">4.3.4.2 Reduce</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-5-%E5%A4%9A%E6%B5%81%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="nav-number">4.3.5.</span> <span class="nav-text">4.3.5 多流转换算子</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-5-1-Connect-amp-amp-CoMap-amp-amp-CoFlatMap"><span class="nav-number">4.3.5.1.</span> <span class="nav-text">4.3.5.1 Connect&amp;&amp;CoMap&amp;&amp;CoFlatMap</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-5-2-Union"><span class="nav-number">4.3.5.2.</span> <span class="nav-text">4.3.5.2 Union</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-Flink%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">4.4.</span> <span class="nav-text">4.4 Flink支持的数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-1-%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">4.4.1.</span> <span class="nav-text">4.4.1 支持的数据类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-2-Java-%E5%85%83%E7%BB%84"><span class="nav-number">4.4.2.</span> <span class="nav-text">4.4.2 Java 元组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-3-POJOs"><span class="nav-number">4.4.3.</span> <span class="nav-text">4.4.3 POJOs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-4-%E5%8E%9F%E5%A7%8B%E7%B1%BB%E5%9E%8B"><span class="nav-number">4.4.4.</span> <span class="nav-text">4.4.4 原始类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-5-%E5%85%B6%E5%AE%83%E7%B1%BB%E5%9E%8B"><span class="nav-number">4.4.5.</span> <span class="nav-text">4.4.5 其它类型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-5-%E5%AE%9E%E7%8E%B0UDF%E5%87%BD%E6%95%B0-%E6%9B%B4%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9A%84%E6%8E%A7%E5%88%B6%E6%B5%81"><span class="nav-number">4.5.</span> <span class="nav-text">4.5 实现UDF函数-更细粒度的控制流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-1-%E5%87%BD%E6%95%B0%E7%B1%BB%EF%BC%88Function-Classes%EF%BC%89"><span class="nav-number">4.5.1.</span> <span class="nav-text">4.5.1 函数类（Function Classes）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-6-Sink"><span class="nav-number">4.6.</span> <span class="nav-text">4.6 Sink</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-1-kafka-Sink"><span class="nav-number">4.6.1.</span> <span class="nav-text">4.6.1 kafka Sink</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-2-Redis-Sink"><span class="nav-number">4.6.2.</span> <span class="nav-text">4.6.2 Redis Sink</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-3-JDBC-Sink"><span class="nav-number">4.6.3.</span> <span class="nav-text">4.6.3 JDBC Sink</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Flink-Window-API"><span class="nav-number">5.</span> <span class="nav-text">5 Flink Window API</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-Window-%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 Window 的生命周期</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-Flink-%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E7%AA%97%E5%8F%A3"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 Flink 中常见的窗口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 滚动窗口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="nav-number">5.4.</span> <span class="nav-text">5.4 滑动窗口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3"><span class="nav-number">5.5.</span> <span class="nav-text">5.5 会话窗口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-6-%E5%85%A8%E5%B1%80%E7%AA%97%E5%8F%A3"><span class="nav-number">5.6.</span> <span class="nav-text">5.6 全局窗口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-7-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="nav-number">5.7.</span> <span class="nav-text">5.7 窗口函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-1-Reduce-Function"><span class="nav-number">5.7.1.</span> <span class="nav-text">5.7.1 Reduce Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-2-Aggregate-Function"><span class="nav-number">5.7.2.</span> <span class="nav-text">5.7.2 Aggregate Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-3-ProcessWindowFunction"><span class="nav-number">5.7.3.</span> <span class="nav-text">5.7.3 ProcessWindowFunction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-4-%E5%85%B7%E6%9C%89%E5%A2%9E%E9%87%8F%E8%81%9A%E5%90%88%E7%9A%84ProcessWindowFunction"><span class="nav-number">5.7.4.</span> <span class="nav-text">5.7.4 具有增量聚合的ProcessWindowFunction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-5-%E8%A7%A6%E5%8F%91%E5%99%A8"><span class="nav-number">5.7.5.</span> <span class="nav-text">5.7.5 触发器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-6-%E7%A7%BB%E9%99%A4%E5%99%A8"><span class="nav-number">5.7.6.</span> <span class="nav-text">5.7.6 移除器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-7-%E5%85%81%E8%AE%B8%E5%A4%84%E7%90%86%E8%BF%9F%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="nav-number">5.7.7.</span> <span class="nav-text">5.7.7 允许处理迟到的数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-8-%E5%B0%86%E8%BF%9F%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E6%94%BE%E5%85%A5%E4%BE%A7%E8%BE%93%E5%87%BA%E6%B5%81"><span class="nav-number">5.7.8.</span> <span class="nav-text">5.7.8 将迟到的数据放入侧输出流</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-7-9-%E8%8E%B7%E5%8F%96%E4%BE%A7%E8%BE%93%E5%87%BA%E6%B5%81"><span class="nav-number">5.7.9.</span> <span class="nav-text">5.7.9 获取侧输出流</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%92%8C-watermark"><span class="nav-number">6.</span> <span class="nav-text">6 时间语义和 watermark</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 时间语义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-Event-Time%E5%92%8CWatermarks"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 Event Time和Watermarks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-watermark%E7%9A%84%E4%BC%A0%E9%80%92"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 watermark的传递</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-watermark%E4%BB%A3%E7%A0%81%E6%A1%88%E4%BE%8B"><span class="nav-number">6.4.</span> <span class="nav-text">6.4 watermark代码案例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-Flink-%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86"><span class="nav-number">7.</span> <span class="nav-text">7 Flink 状态管理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-Flink%E4%B8%AD%E7%9A%84%E7%8A%B6%E6%80%81"><span class="nav-number">7.1.</span> <span class="nav-text">7.1 Flink中的状态</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">yimisiyang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/gitblog/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yimisiyang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/gitblog/lib/anime.min.js"></script>
  <script src="/gitblog/lib/velocity/velocity.min.js"></script>
  <script src="/gitblog/lib/velocity/velocity.ui.min.js"></script>

<script src="/gitblog/js/utils.js"></script>

<script src="/gitblog/js/motion.js"></script>


<script src="/gitblog/js/schemes/muse.js"></script>


<script src="/gitblog/js/next-boot.js"></script>




  















  

  

</body>
</html>
